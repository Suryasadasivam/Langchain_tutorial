{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cc8908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api key found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() #load api \n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"api key found\")\n",
    "else:\n",
    "    print(\"api key not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14d682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai_model=\"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abf864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(temperature=0.0,model=openai_model,api_key=OPENAI_API_KEY) # temperature for creativeness \n",
    "\n",
    "creative_llm = ChatOpenAI(temperature=0.9, model=openai_model,api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7c004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory # abstract base class that defines the interface for chat message history implementations.\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory # concrete implementation of BaseChatMessageHistory that stores messages in memory (RAM)\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory # A wrapper that allows you to attach message history to a LangChain Runnable.\n",
    "from langchain_core.messages import AIMessage # message class representing a message generated by the AI/LLM (Language Model) in a conversation.\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74c09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke([\n",
    "    HumanMessage(content=\"Hi! I am cristanio\"),\n",
    "    AIMessage(content=\"Hello cristanio, How can i assist you today\"),\n",
    "    HumanMessage(content=\"what is my name\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd7339f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Cristanio. How can I assist you today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7eaa432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Cristanio. How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72d66fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "596dee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\": {\"session_id\":\"first_chat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bdeaf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, David Billa! How can I assist you today?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RunnableWithMessageHistory(llm, get_session_history)\n",
    "model.invoke([HumanMessage(content=\"Hi I am david billa\")],config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e8fba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is David Billa. How can I help you today?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"what is my name\")],config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2efe52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_chat': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi I am david billa', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, David Billa! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CArnsz0vtkis9kbzVvwxhQOk22CEU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--010c82c9-f51e-4609-9515-bfa643b70d2b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is David Billa. How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 38, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CAropa6pd2oPLAfJAg2TLfXA0Vbo0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53587840-265b-4aad-add1-0ec8dde800d8-0', usage_metadata={'input_tokens': 38, 'output_tokens': 14, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42437087",
   "metadata": {},
   "outputs": [],
   "source": [
    "configg={\"configurable\":{\"session_id\":\"second_chat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de8aacab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about you unless you share it with me. How can I assist you today?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"what is my name\")],config=configg).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc7d3816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_chat': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi I am david billa', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, David Billa! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CArnsz0vtkis9kbzVvwxhQOk22CEU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--010c82c9-f51e-4609-9515-bfa643b70d2b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is David Billa. How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 38, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CAropa6pd2oPLAfJAg2TLfXA0Vbo0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53587840-265b-4aad-add1-0ec8dde800d8-0', usage_metadata={'input_tokens': 38, 'output_tokens': 14, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is David Billa. If you have any other questions or need assistance, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 64, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CArqatcVAN13qJxvaUtkIV6hPp5rx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7079f2b2-2c2e-43a9-8981-7b65517e2abc-0', usage_metadata={'input_tokens': 64, 'output_tokens': 22, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]),\n",
       " 'second_chat': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm sorry, but I don't have access to personal information about you unless you share it with me. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 11, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d77b305a29', 'id': 'chatcmpl-CArqigLGGoas0SoaCvCd6mQ8QCBUK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--433cc218-ef70-4df1-bf7d-06e5f88d3535-0', usage_metadata={'input_tokens': 11, 'output_tokens': 27, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0283877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are a helpful assistant. answer all the question to the best of your knowledge\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "827c50f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain =prompt | llm\n",
    "\n",
    "chain.invoke({\"messages\":[\"hi i am bob\"]}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10bb2e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about you, including your name. How can I assist you today?\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"what is my name\")]}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63d4c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "configgg={\"configurable\":{\"session_id\":\"third_chat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccbe44c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Jim! How can I assist you today?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "respone=model.invoke([HumanMessage(content=\"Hi my name is jim\")],config=configgg)\n",
    "\n",
    "respone.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efd1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "respone=model.invoke([HumanMessage(content=\"What is my name\")],config=configgg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7e7ee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Jim. How can I help you today, Jim?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cdcf86",
   "metadata": {},
   "source": [
    "**trimming the conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91c41268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3613eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16b43855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens_from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39d6a2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9198537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens_from_messages(trimmer.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392bc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x109cebba0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are a helpful assistant. answer all the question to the best of your knowledge'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05fe4d",
   "metadata": {},
   "source": [
    "**Langchain with conversation Buffer memory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca68d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/2xjjcspd5r3dz1m4ll_0c7m80000gn/T/ipykernel_6027/629970898.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory=ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d6c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"hi\"},{\"output\":\"what's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe06cacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: what's up\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fff3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='HI', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"what's up\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2=ConversationBufferMemory(return_messages=True)\n",
    "memory2.save_context({\"input\":\"HI\"},{\"output\":\"what's up\"})\n",
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdd0abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/2xjjcspd5r3dz1m4ll_0c7m80000gn/T/ipykernel_6027/950388216.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation=ConversationChain(llm=llm,verbose=True,memory=ConversationBufferMemory())\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation=ConversationChain(llm=llm,verbose=True,memory=ConversationBufferMemory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4276ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! my name is bob\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there! my name is bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f284e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! my name is bob\n",
      "AI: Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\n",
      "Human: tell me 5 points about Databricks\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure, Bob! Here are five key points about Databricks:\\n\\n1. **Unified Analytics Platform**: Databricks is designed to unify data engineering, data science, and machine learning workflows. It provides a collaborative environment where teams can work together on data projects using a single platform.\\n\\n2. **Apache Spark Integration**: At its core, Databricks is built on Apache Spark, which is a powerful open-source engine for big data processing. This allows users to perform large-scale data processing and analytics efficiently.\\n\\n3. **Collaborative Notebooks**: Databricks offers interactive notebooks that support multiple languages, including Python, R, Scala, and SQL. These notebooks allow users to write code, visualize data, and share insights in a collaborative manner.\\n\\n4. **Delta Lake**: Databricks includes Delta Lake, an open-source storage layer that brings ACID transactions to big data workloads. This helps ensure data reliability and consistency, making it easier to manage large datasets.\\n\\n5. **Cloud Integration**: Databricks is available on major cloud platforms like AWS, Azure, and Google Cloud, allowing users to leverage cloud resources for scalable data processing and analytics. This flexibility makes it suitable for various use cases, from data engineering to machine learning.\\n\\nIf you have any more questions about Databricks or anything else, feel free to ask!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"tell me 5 points about Databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c74d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there! my name is bob', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='tell me 5 points about Databricks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sure, Bob! Here are five key points about Databricks:\\n\\n1. **Unified Analytics Platform**: Databricks is designed to unify data engineering, data science, and machine learning workflows. It provides a collaborative environment where teams can work together on data projects using a single platform.\\n\\n2. **Apache Spark Integration**: At its core, Databricks is built on Apache Spark, which is a powerful open-source engine for big data processing. This allows users to perform large-scale data processing and analytics efficiently.\\n\\n3. **Collaborative Notebooks**: Databricks offers interactive notebooks that support multiple languages, including Python, R, Scala, and SQL. These notebooks allow users to write code, visualize data, and share insights in a collaborative manner.\\n\\n4. **Delta Lake**: Databricks includes Delta Lake, an open-source storage layer that brings ACID transactions to big data workloads. This helps ensure data reliability and consistency, making it easier to manage large datasets.\\n\\n5. **Cloud Integration**: Databricks is available on major cloud platforms like AWS, Azure, and Google Cloud, allowing users to leverage cloud resources for scalable data processing and analytics. This flexibility makes it suitable for various use cases, from data engineering to machine learning.\\n\\nIf you have any more questions about Databricks or anything else, feel free to ask!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b601ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! my name is bob\n",
      "AI: Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\n",
      "Human: tell me 5 points about Databricks\n",
      "AI: Sure, Bob! Here are five key points about Databricks:\n",
      "\n",
      "1. **Unified Analytics Platform**: Databricks is designed to unify data engineering, data science, and machine learning workflows. It provides a collaborative environment where teams can work together on data projects using a single platform.\n",
      "\n",
      "2. **Apache Spark Integration**: At its core, Databricks is built on Apache Spark, which is a powerful open-source engine for big data processing. This allows users to perform large-scale data processing and analytics efficiently.\n",
      "\n",
      "3. **Collaborative Notebooks**: Databricks offers interactive notebooks that support multiple languages, including Python, R, Scala, and SQL. These notebooks allow users to write code, visualize data, and share insights in a collaborative manner.\n",
      "\n",
      "4. **Delta Lake**: Databricks includes Delta Lake, an open-source storage layer that brings ACID transactions to big data workloads. This helps ensure data reliability and consistency, making it easier to manage large datasets.\n",
      "\n",
      "5. **Cloud Integration**: Databricks is available on major cloud platforms like AWS, Azure, and Google Cloud, allowing users to leverage cloud resources for scalable data processing and analytics. This flexibility makes it suitable for various use cases, from data engineering to machine learning.\n",
      "\n",
      "If you have any more questions about Databricks or anything else, feel free to ask!\n",
      "Human: give me one point on hoe databricks better than synapse\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"One point where Databricks may have an advantage over Azure Synapse is its **collaborative environment for data science and machine learning**. Databricks provides interactive notebooks that support multiple programming languages and allow for real-time collaboration among team members. This feature is particularly beneficial for data scientists and analysts who need to work together on projects, share insights, and iterate quickly. While Azure Synapse also offers collaborative features, many users find Databricks' notebook interface to be more intuitive and user-friendly for data exploration and experimentation.\\n\\nIf you have more questions or need further comparisons, just let me know!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input= \"give me one point on hoe databricks better than synapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6005aa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there! my name is bob', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='tell me 5 points about Databricks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sure, Bob! Here are five key points about Databricks:\\n\\n1. **Unified Analytics Platform**: Databricks is designed to unify data engineering, data science, and machine learning workflows. It provides a collaborative environment where teams can work together on data projects using a single platform.\\n\\n2. **Apache Spark Integration**: At its core, Databricks is built on Apache Spark, which is a powerful open-source engine for big data processing. This allows users to perform large-scale data processing and analytics efficiently.\\n\\n3. **Collaborative Notebooks**: Databricks offers interactive notebooks that support multiple languages, including Python, R, Scala, and SQL. These notebooks allow users to write code, visualize data, and share insights in a collaborative manner.\\n\\n4. **Delta Lake**: Databricks includes Delta Lake, an open-source storage layer that brings ACID transactions to big data workloads. This helps ensure data reliability and consistency, making it easier to manage large datasets.\\n\\n5. **Cloud Integration**: Databricks is available on major cloud platforms like AWS, Azure, and Google Cloud, allowing users to leverage cloud resources for scalable data processing and analytics. This flexibility makes it suitable for various use cases, from data engineering to machine learning.\\n\\nIf you have any more questions about Databricks or anything else, feel free to ask!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='give me one point on hoe databricks better than synapse', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"One point where Databricks may have an advantage over Azure Synapse is its **collaborative environment for data science and machine learning**. Databricks provides interactive notebooks that support multiple programming languages and allow for real-time collaboration among team members. This feature is particularly beneficial for data scientists and analysts who need to work together on projects, share insights, and iterate quickly. While Azure Synapse also offers collaborative features, many users find Databricks' notebook interface to be more intuitive and user-friendly for data exploration and experimentation.\\n\\nIf you have more questions or need further comparisons, just let me know!\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0617228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! my name is bob\n",
      "AI: Hello, Bob! It's great to meet you! I'm here to chat and help with anything you might need. How's your day going so far?\n",
      "Human: tell me 5 points about Databricks\n",
      "AI: Sure, Bob! Here are five key points about Databricks:\n",
      "\n",
      "1. **Unified Analytics Platform**: Databricks is designed to unify data engineering, data science, and machine learning workflows. It provides a collaborative environment where teams can work together on data projects using a single platform.\n",
      "\n",
      "2. **Apache Spark Integration**: At its core, Databricks is built on Apache Spark, which is a powerful open-source engine for big data processing. This allows users to perform large-scale data processing and analytics efficiently.\n",
      "\n",
      "3. **Collaborative Notebooks**: Databricks offers interactive notebooks that support multiple languages, including Python, R, Scala, and SQL. These notebooks allow users to write code, visualize data, and share insights in a collaborative manner.\n",
      "\n",
      "4. **Delta Lake**: Databricks includes Delta Lake, an open-source storage layer that brings ACID transactions to big data workloads. This helps ensure data reliability and consistency, making it easier to manage large datasets.\n",
      "\n",
      "5. **Cloud Integration**: Databricks is available on major cloud platforms like AWS, Azure, and Google Cloud, allowing users to leverage cloud resources for scalable data processing and analytics. This flexibility makes it suitable for various use cases, from data engineering to machine learning.\n",
      "\n",
      "If you have any more questions about Databricks or anything else, feel free to ask!\n",
      "Human: give me one point on hoe databricks better than synapse\n",
      "AI: One point where Databricks may have an advantage over Azure Synapse is its **collaborative environment for data science and machine learning**. Databricks provides interactive notebooks that support multiple programming languages and allow for real-time collaboration among team members. This feature is particularly beneficial for data scientists and analysts who need to work together on projects, share insights, and iterate quickly. While Azure Synapse also offers collaborative features, many users find Databricks' notebook interface to be more intuitive and user-friendly for data exploration and experimentation.\n",
      "\n",
      "If you have more questions or need further comparisons, just let me know!\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your name is Bob! If there's anything else you'd like to chat about or ask, feel free to let me know!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cb922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
